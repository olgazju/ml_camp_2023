{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-26 17:23:10--  https://github.com/alexeygrigorev/large-datasets/releases/download/wasps-bees/bees-wasps.h5\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/426348925/05aeef6d-6432-4320-a521-025803848f49?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231126%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231126T152311Z&X-Amz-Expires=300&X-Amz-Signature=7f5741e891c1ece6e6562da09b632f631c1c7c3517156eb540ed348c623fa4b3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=426348925&response-content-disposition=attachment%3B%20filename%3Dbees-wasps.h5&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-11-26 17:23:11--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/426348925/05aeef6d-6432-4320-a521-025803848f49?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231126%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231126T152311Z&X-Amz-Expires=300&X-Amz-Signature=7f5741e891c1ece6e6562da09b632f631c1c7c3517156eb540ed348c623fa4b3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=426348925&response-content-disposition=attachment%3B%20filename%3Dbees-wasps.h5&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 89753864 (86M) [application/octet-stream]\n",
      "Saving to: ‘bees-wasps.h5’\n",
      "\n",
      "bees-wasps.h5       100%[===================>]  85.60M  36.3MB/s    in 2.4s    \n",
      "\n",
      "2023-11-26 17:23:13 (36.3 MB/s) - ‘bees-wasps.h5’ saved [89753864/89753864]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/alexeygrigorev/large-datasets/releases/download/wasps-bees/bees-wasps.h5 -O bees-wasps.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 17:27:44.513710: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Now convert this model from Keras to TF-Lite format.\n",
    "\n",
    "What's the size of the converted model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_g/dcc1mh151c37cqym56jdsb0w0000gn/T/tmp909puhqe/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_g/dcc1mh151c37cqym56jdsb0w0000gn/T/tmp909puhqe/assets\n",
      "2023-11-26 17:28:57.177478: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-11-26 17:28:57.178098: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-11-26 17:28:57.178943: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/_g/dcc1mh151c37cqym56jdsb0w0000gn/T/tmp909puhqe\n",
      "2023-11-26 17:28:57.180316: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-11-26 17:28:57.180330: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/_g/dcc1mh151c37cqym56jdsb0w0000gn/T/tmp909puhqe\n",
      "2023-11-26 17:28:57.184121: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2023-11-26 17:28:57.185463: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-11-26 17:28:57.312478: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/_g/dcc1mh151c37cqym56jdsb0w0000gn/T/tmp909puhqe\n",
      "2023-11-26 17:28:57.326410: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 147468 microseconds.\n",
      "2023-11-26 17:28:57.346904: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 7, Total Ops 16, % non-converted = 43.75 %\n",
      " * 7 ARITH ops\n",
      "\n",
      "- arith.constant:    7 occurrences  (f32: 6, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('bees-wasps.h5')\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('bees-wasps.tflite', 'wb') as f_out:\n",
    "    f_out.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "To be able to use this model, we need to know the index of the input and the index of the output.\n",
    "\n",
    "What's the output index for this model?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.lite as tflite\n",
    "\n",
    "interpreter = tflite.Interpreter(model_path='bees-wasps.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']\n",
    "print(output_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-26 17:36:22--  https://habrastorage.org/webt/rt/d9/dh/rtd9dhsmhwrdezeldzoqgijdg8a.jpeg\n",
      "Resolving habrastorage.org (habrastorage.org)... 51.89.30.72\n",
      "Connecting to habrastorage.org (habrastorage.org)|51.89.30.72|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 425350 (415K) [image/jpeg]\n",
      "Saving to: ‘rtd9dhsmhwrdezeldzoqgijdg8a.jpeg’\n",
      "\n",
      "rtd9dhsmhwrdezeldzo 100%[===================>] 415.38K  2.60MB/s    in 0.2s    \n",
      "\n",
      "2023-11-26 17:36:23 (2.60 MB/s) - ‘rtd9dhsmhwrdezeldzoqgijdg8a.jpeg’ saved [425350/425350]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://habrastorage.org/webt/rt/d9/dh/rtd9dhsmhwrdezeldzoqgijdg8a.jpeg -O rtd9dhsmhwrdezeldzoqgijdg8a.jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94509804, 0.9098039 , 0.8509804 ], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with request.urlopen('https://habrastorage.org/webt/rt/d9/dh/rtd9dhsmhwrdezeldzoqgijdg8a.jpeg') as resp:\n",
    "    buffer = resp.read()\n",
    "stream = BytesIO(buffer)\n",
    "img = Image.open(stream)\n",
    "\n",
    "img = img.resize((150, 150), Image.NEAREST)\n",
    "img_array = np.array(img, dtype=np.float32)\n",
    "img_array = img_array / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6592143]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(img_array)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dress': 0.4453350603580475}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://localhost:8080/2015-03-31/functions/function/invocations'\n",
    "\n",
    "data = {'url': 'https://habrastorage.org/webt/rt/d9/dh/rtd9dhsmhwrdezeldzoqgijdg8a.jpeg'}\n",
    "\n",
    "result = requests.post(url, json=data).json()\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_camp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
