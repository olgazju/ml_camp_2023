{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Movie Data Collection Script\n",
    "\n",
    "This script is devised to fetch movie-related data from TheMovieDB API and, using the `imdb_id`, obtain metadata from the OMDB API, merge the datasets, and store the collected data in Parquet format. Additionally, it creates a dataset of credits from TheMovieDB API. Below is a breakdown of its functionalities:\n",
    "\n",
    "### 1. **Importing Required Libraries**:\n",
    "   - Essential libraries such as `requests`, `os`, `backoff`, and `pandas` are imported to handle HTTP requests, manage environment variables, implement retry logic, and manipulate data respectively.\n",
    "\n",
    "### 2. **Header Configuration**:\n",
    "   - HTTP headers are configured for authorization using an API token retrieved from environment variables. Obtain the token access from [TheMovieDB API](https://developer.themoviedb.org/reference/intro/getting-started) and the OMDB API key from [OMDB API](https://www.omdbapi.com/apikey.aspx). Note: The OMDB API key is limited to 1000 calls per day for free.\n",
    "   - After acquiring the keys, create a `.env` file in the root folder and populate it with the following values:\n",
    "\n",
    "        ```plaintext\n",
    "        API_KEY=\n",
    "        API_TOKEN=\n",
    "        OMDB_KEY=\n",
    "        ```\n",
    "\n",
    "### 3. **Retry Logic**:\n",
    "   - Custom retry logic is defined using the `backoff` library to handle HTTP errors, particularly focusing on status code 429 (Too Many Requests).\n",
    "\n",
    "### 4. **API Call Function**:\n",
    "   - A function `call_get(url)` is outlined to make GET requests to the specified URL and to raise exceptions for unsuccessful responses.\n",
    "\n",
    "### 5. **Movie Data Retrieval Functions**:\n",
    "   - `get_latest_movie()`: Fetches the latest movie data from TheMovieDB API.\n",
    "   - `get_movie_credits_by_id(id)`: Obtains movie credits based on the movie ID from TheMovieDB API, with error handling for non-existent movie IDs.\n",
    "   - `get_movie_by_id(id)`: Retrieves movie data by ID from TheMovieDB API, also with error handling for non-existent movie IDs.\n",
    "   - `get_movie_from_omdb(imdb_id, api_key)`: Fetches movie data from the OMDB API using the IMDb ID.\n",
    "\n",
    "### 6. **Bulk Data Collection Functions**:\n",
    "   - `fetch_all_movies(start_id, last_id)` and `fetch_all_credits(start_id, last_id)` are crafted to loop through a range of movie IDs, collecting and merging movie data from both TheMovieDB and OMDB APIs, and movie credits from TheMovieDB API respectively.\n",
    "\n",
    "### 7. **Data Normalization and Storage**:\n",
    "   - The script utilizes `pandas` to normalize the collected JSON data into a tabular format and subsequently stores the data in Parquet files with gzip compression, for both movies and credits data.\n",
    "\n",
    "This script showcases a systematic approach to collecting, normalizing, and storing movie-related data from various online sources through API interactions. It employs robust error handling and retry logic to ensure the reliability of the data collection process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import backoff\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional, Union, Dict, List\n",
    "\n",
    "load_dotenv('../.env')\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {os.getenv('API_TOKEN')}\"\n",
    "}\n",
    "\n",
    "\n",
    "# Custom retry condition to handle HTTP 429 status code (Too Many Requests)\n",
    "def giveup(exc: requests.exceptions.HTTPError) -> bool:\n",
    "    \"\"\"Determines whether to give up a retry attempt.\n",
    "    \n",
    "    Args:\n",
    "        exc (requests.exceptions.HTTPError): The exception raised during the HTTP request.\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if the exception's status code is not 429 - Too Many Requests, otherwise False.\n",
    "    \"\"\"\n",
    "    return exc.response.status_code != 429\n",
    "\n",
    "\n",
    "@backoff.on_exception(\n",
    "    backoff.expo,  # Exponential backoff strategy for Too Many Requests error\n",
    "    requests.exceptions.HTTPError,  # Exception to look for\n",
    "    max_tries=10,  # Maximum retry attempts\n",
    "    giveup=giveup  # Function to determine if retry should be aborted\n",
    ")\n",
    "def call_get(url: str) -> Union[Dict, None]:\n",
    "    \"\"\"Makes a GET request to a specified URL and handles potential errors.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The URL to send a GET request to.\n",
    "        \n",
    "    Returns:\n",
    "        dict: The JSON response from the GET request.\n",
    "    \"\"\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status() \n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def get_latest_movie() -> Dict:\n",
    "    \"\"\"Fetches the latest movie data from TheMovieDB API.\n",
    "    \n",
    "    Returns:\n",
    "        dict: The latest movie data.\n",
    "    \"\"\"\n",
    "    url = \"https://api.themoviedb.org/3/movie/latest\"\n",
    "    return call_get(url)\n",
    "\n",
    "\n",
    "def get_movie_credits_by_id(id: int) -> Optional[Dict]:\n",
    "    \"\"\"Obtains movie credits based on the movie ID from TheMovieDB API.\n",
    "    \n",
    "    Args:\n",
    "        id (int): The ID of the movie.\n",
    "        \n",
    "    Returns:\n",
    "        dict: The movie credits data, or None if not found.\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"https://api.themoviedb.org/3/movie/{id}/credits?language=en-US\"\n",
    "    try:\n",
    "        return call_get(url)\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if e.response.status_code == 404:\n",
    "            try:\n",
    "                error_response = e.response.json()\n",
    "                if error_response.get('status_code') == 34:\n",
    "                    print(f\"No credits found for ID: {id}\")\n",
    "                    return None\n",
    "                \n",
    "            except ValueError:\n",
    "                print(f\"Received unexpected response: {e.response.text}\")\n",
    "        else:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            raise e\n",
    "\n",
    "\n",
    "def get_movie_by_id(id: int) -> Optional[Dict]:\n",
    "    \"\"\"Retrieves movie data by ID from TheMovieDB API.\n",
    "    \n",
    "    Args:\n",
    "        id (int): The ID of the movie.\n",
    "        \n",
    "    Returns:\n",
    "        dict: The movie data, or None if not found.\n",
    "    \"\"\"\n",
    "    url = f\"https://api.themoviedb.org/3/movie/{id}?language=en-US\"\n",
    "    try:\n",
    "        return call_get(url)\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if e.response.status_code == 404:\n",
    "            try:\n",
    "                error_response = e.response.json()\n",
    "                if error_response.get('status_code') == 34:\n",
    "                    print(f\"No movie found for ID: {id}\")\n",
    "                    return None\n",
    "                \n",
    "            except ValueError:\n",
    "                print(f\"Received unexpected response: {e.response.text}\")\n",
    "        else:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            raise e\n",
    "\n",
    "def get_movie_from_omdb(imdb_id: str, api_key: str = os.getenv('OMDB_KEY')) -> Dict:\n",
    "    \"\"\"Fetches movie data from the OMDB API using the IMDb ID.\n",
    "    \n",
    "    Args:\n",
    "        imdb_id (str): The IMDb ID of the movie.\n",
    "        api_key (str): The API key for OMDB API.\n",
    "        \n",
    "    Returns:\n",
    "        dict: The movie data from OMDB API.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.omdbapi.com/?i={imdb_id}&apikey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status() \n",
    "    return response.json()\n",
    "\n",
    "def fetch_all_movies(start_id: int, last_id: int) -> List[Dict]:\n",
    "    \"\"\"Loops through a range of movie IDs, collecting and merging movie data from both APIs.\n",
    "    \n",
    "    Args:\n",
    "        start_id (int): The starting movie ID.\n",
    "        last_id (int): The ending movie ID.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of merged movie data dictionaries.\n",
    "    \"\"\"\n",
    "    all_movies = [] \n",
    "    for id in range(start_id, last_id + 1): \n",
    "        movie = get_movie_by_id(id)\n",
    "        if movie is not None and movie[\"imdb_id\"] and \\\n",
    "            movie['revenue'] !=0 and movie['status'] == 'Released' and \\\n",
    "            movie ['budget'] !=0:\n",
    "            # check this movie in omdb\n",
    "            try: \n",
    "                omdb_json = get_movie_from_omdb(movie[\"imdb_id\"])\n",
    "                merged = {**movie, **omdb_json}\n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                print(f\"OMDB Received response: {e.response.text}\")\n",
    "            all_movies.append(merged)\n",
    "    return all_movies\n",
    "\n",
    "def fetch_all_credits(start_id: int, last_id: int) -> List[Dict]:\n",
    "    \"\"\"Loops through a range of movie IDs, collecting movie credits data from TheMovieDB API.\n",
    "    \n",
    "    Args:\n",
    "        start_id (int): The starting movie ID.\n",
    "        last_id (int): The ending movie ID.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of movie credits data dictionaries.\n",
    "    \"\"\"\n",
    "    all_credits = [] \n",
    "    for id in range(start_id, last_id + 1):  \n",
    "        credit = get_movie_credits_by_id(id)\n",
    "        if credit is not None:\n",
    "            all_credits.append(credit)\n",
    "    return all_credits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the lastest avaliable movie id from TMDB API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_movie = get_latest_movie()['id']\n",
    "last_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ID of the last movie to be fetched\n",
    "last_movie = 45000\n",
    "\n",
    "# Set the ID of the movie to start fetching\n",
    "start_movie = 43001\n",
    "\n",
    "# Fetch all movies metadata from ID start_movie to last_movie\n",
    "all_movies = fetch_all_movies(start_movie, last_movie)\n",
    "\n",
    "df = pd.json_normalize(all_movies)\n",
    "df.to_parquet(f\"../tmdb/movies_{last_movie}.parquet\", compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ID of the last movie to be fetched\n",
    "last_movie = 45000\n",
    "\n",
    "# Set the ID of the movie to start fetching\n",
    "start_movie = 43001\n",
    "\n",
    "# Fetch all credits from ID start_movie to last_movie\n",
    "all_movies = fetch_all_credits(start_movie, last_movie)\n",
    "\n",
    "df = pd.json_normalize(all_movies)\n",
    "df.to_parquet(f\"../credits/credits_{last_movie}.parquet\", compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "\n",
    "def read_parquet_files_to_dataframe(directory_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Reads all parquet files from a specified directory and merges them into a single DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        directory_path (str): The path to the directory containing the parquet files.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the merged data from all parquet files.\n",
    "    \"\"\"\n",
    "    # List all files in the directory\n",
    "    files = [f for f in os.listdir(directory_path) if f.endswith('.parquet')]\n",
    "    \n",
    "    dataframes = []\n",
    "    \n",
    "    # Loop through the files and read each one into a DataFrame\n",
    "    for file in files:\n",
    "        file_path = os.path.join(directory_path, file)\n",
    "        parquet_file = pq.ParquetFile(file_path)\n",
    "        df = parquet_file.read().to_pandas()\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    # Concatenate all the DataFrames into a single DataFrame\n",
    "    merged_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    return merged_dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOVIES\n",
    "# Call the function to read and merge all parquet files in the specified directory into a DataFrame\n",
    "movies_dataframe = read_parquet_files_to_dataframe('../tmdb/')\n",
    "# Remove duplicate rows based on the 'id' column of the DataFrame\n",
    "movies_dataframe=movies_dataframe.drop_duplicates(subset=['id'])\n",
    "# TODO: remove this line and tmdb and credits folder\n",
    "movies_dataframe = movies_dataframe[(movies_dataframe['revenue'] != 0) & (movies_dataframe['budget'] != 0)\n",
    "                                    & (movies_dataframe['status'] == 'Released')]\n",
    "# Save the deduplicated DataFrame to a new Parquet file with gzip compression in the specified directory\n",
    "movies_dataframe.to_parquet('../data/movies.parquet', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREDITS\n",
    "# Call the function to read and merge all parquet files in the specified directory into a DataFrame\n",
    "credits_dataframe = read_parquet_files_to_dataframe('../credits/')\n",
    "# Remove duplicate rows based on the 'id' column of the DataFrame\n",
    "credits_dataframe=credits_dataframe.drop_duplicates(subset=['id'])\n",
    "# Save the deduplicated DataFrame to a new Parquet file with gzip compression in the specified directory\n",
    "credits_dataframe.to_parquet('../data/credits.parquet', compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_camp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
