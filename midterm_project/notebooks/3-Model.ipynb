{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Notebook\n",
    "\n",
    "Welcome to the Modeling Notebook. This notebook focuses on building and evaluating machine learning models based on the insights gained from EDA.\n",
    "\n",
    "## Objectives:\n",
    "- **Model Selection**: Trying out different models to see which one performs the best.\n",
    "- **Model Tuning**: Optimizing the performance of the selected model.\n",
    "- **Model Evaluation**: Assessing the performance of the model using appropriate metrics.\n",
    "\n",
    "## Dataset:\n",
    "In this notebook, we will be working with the cleaned dataset located at `./data/features/movies_dataset.parquet`, which is the result of feature engineering process in the preceding EDA Notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "release_year                   object\n",
       "release_month                  object\n",
       "runtime                         int64\n",
       "rated                          object\n",
       "collection                      int64\n",
       "is_english                      int64\n",
       "title_vector                  float64\n",
       "overview_vector               float64\n",
       "tagline_vector                float64\n",
       "plot_vector                   float64\n",
       "overview_sentiment            float64\n",
       "title_sentiment               float64\n",
       "tagline_sentiment             float64\n",
       "plot_sentiment                float64\n",
       "era                          category\n",
       "is_summer                       int64\n",
       "is_autumn                       int64\n",
       "action                          int64\n",
       "adventure                       int64\n",
       "animation                       int64\n",
       "comedy                          int64\n",
       "crime                           int64\n",
       "drama                           int64\n",
       "family                          int64\n",
       "fantasy                         int64\n",
       "history                         int64\n",
       "horror                          int64\n",
       "music                           int64\n",
       "mystery                         int64\n",
       "romance                         int64\n",
       "science fiction                 int64\n",
       "thriller                        int64\n",
       "war                             int64\n",
       "western                         int64\n",
       "num_spoken_languages            int64\n",
       "num_genres                      int64\n",
       "num_production_companies        int64\n",
       "num_production_countries        int64\n",
       "is_foreign                      int64\n",
       "director_popularity           float64\n",
       "writer_popularity             float64\n",
       "producer_popularity           float64\n",
       "average_crew_popularity       float64\n",
       "number_crew_members           float64\n",
       "average_cast_popularity       float64\n",
       "number_cast_members           float64\n",
       "top_cast_popularity           float64\n",
       "numerical_ROI_category          int64\n",
       "numerical_rating_category       int64\n",
       "numerical_award_category        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('dataset.parquet')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "labels = ['numerical_ROI_category', 'numerical_rating_category', 'numerical_award_category']\n",
    "\n",
    "features = ['release_year', 'release_month', 'runtime', 'rated', 'collection', \n",
    "                 'is_english', 'title_vector',\n",
    "                'overview_vector', 'tagline_vector', 'plot_vector',\n",
    "                'overview_sentiment', 'title_sentiment', 'tagline_sentiment',\n",
    "                'plot_sentiment', 'era', 'is_summer', 'is_autumn',\n",
    "                'action', 'adventure', 'animation', 'comedy', 'crime', 'drama',\n",
    "                'family', 'fantasy', 'history', 'horror', 'music', 'mystery', 'romance',\n",
    "                'science fiction', 'thriller', 'war', 'western', 'num_spoken_languages',\n",
    "                'num_genres', 'num_production_companies', 'num_production_countries',\n",
    "                'is_foreign', 'director_popularity', 'writer_popularity',\n",
    "                'producer_popularity', 'average_crew_popularity', 'number_crew_members',\n",
    "                'average_cast_popularity', 'number_cast_members',\n",
    "                'top_cast_popularity']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "labels = ['numerical_ROI_category', 'numerical_rating_category', 'numerical_award_category']\n",
    "\n",
    "features = ['release_year', 'release_month', 'runtime', 'rated', 'collection', \n",
    "                 'is_english', 'title_vector',\n",
    "                'overview_vector', 'tagline_vector', 'plot_vector',\n",
    "                'overview_sentiment', 'title_sentiment', 'tagline_sentiment',\n",
    "                'plot_sentiment', 'era', 'is_summer', 'is_autumn',\n",
    "                'action', 'adventure', 'animation', 'comedy', 'crime', 'drama',\n",
    "                'family', 'fantasy', 'history', 'horror', 'music', 'mystery', 'romance',\n",
    "                'science fiction', 'thriller', 'war', 'western', 'num_spoken_languages',\n",
    "                'num_genres', 'num_production_companies', 'num_production_countries',\n",
    "                'is_foreign', 'director_popularity', 'writer_popularity',\n",
    "                'producer_popularity', 'average_crew_popularity', 'number_crew_members',\n",
    "                'average_cast_popularity', 'number_cast_members',\n",
    "                'top_cast_popularity']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    print(f\"Training for {label}\")\n",
    "    \n",
    "    # Logistic Regression\n",
    "    lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    lr.fit(X_train_t, y_train[label])\n",
    "    y_pred = lr.predict(X_val_t)\n",
    "    print(f\"Logistic Regression Accuracy: {accuracy_score(y_val[label], y_pred)}\")\n",
    "\n",
    "\n",
    "    lr_cv_score = cross_val_score(lr, X_train_t, y_train[label], cv=5).mean()\n",
    "    print(f\"Logistic Regression Mean CV Score: {lr_cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'estimator__C': [0.1, 1, 10],\n",
    "    'estimator__solver': ['liblinear', 'newton-cg', 'lbfgs']\n",
    "}\n",
    "\n",
    "for label in labels:\n",
    "    estimator = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "    grid_search = GridSearchCV(estimator, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    grid_search.fit(X_train_t, y_train[label])\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f'Best parameters: {best_params}')\n",
    "\n",
    "    best_score = grid_search.best_score_\n",
    "    print(f'Best cross-validation score: {best_score}')\n",
    "\n",
    "    val_score = grid_search.score(X_val_t, y_val[label])\n",
    "    print(f'Validation score: {val_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "\n",
    "    print(label)\n",
    "\n",
    "    # Train a model using all features\n",
    "    model = LogisticRegression(solver='liblinear', C=1, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train_t, y_train[label])\n",
    "    original_accuracy = accuracy_score(y_val[label], model.predict(X_val_t))\n",
    "    print(\"originalaccuracy:\", original_accuracy)\n",
    "\n",
    "    differences = {}\n",
    "\n",
    "    for feature in features:\n",
    "        # Exclude the feature\n",
    "        cols_to_use = [col for col in X_train.columns if col != feature]\n",
    "        \n",
    "        train_dict = X_train[cols_to_use].to_dict(orient='records')\n",
    "        val_dict = X_val[cols_to_use].to_dict(orient='records')\n",
    "        \n",
    "        dv = DictVectorizer(sparse=False)\n",
    "        X_train_sub = dv.fit_transform(train_dict)\n",
    "        X_val_sub = dv.transform(val_dict)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_sub = scaler.fit_transform(X_train_sub)\n",
    "        X_val_sub = scaler.transform(X_val_sub)\n",
    "        \n",
    "        # Train a model without the feature\n",
    "        model = LogisticRegression(solver='liblinear', C=10, max_iter=1000, random_state=42)\n",
    "        model.fit(X_train_sub, y_train[label])\n",
    "        \n",
    "        accuracy_without_feature = accuracy_score(y_val[label], model.predict(X_val_sub))\n",
    "        differences[feature] = abs(original_accuracy - accuracy_without_feature)\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    acc_df = pd.DataFrame(list(differences.items()), columns=['Feature', 'original_accuracy - accuracy_without_feature'])\n",
    "    acc_df = acc_df.sort_values(by='original_accuracy - accuracy_without_feature', ascending=False)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 12))\n",
    "    sns.barplot(x='original_accuracy - accuracy_without_feature', y='Feature', data=acc_df)\n",
    "    plt.title('original_accuracy - accuracy_without_feature')\n",
    "    plt.xlabel('accuracy diff')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    print(f\"Training for {label}\")\n",
    "    \n",
    "    # Random Forest\n",
    "    rf = RandomForestClassifier(random_state=42, n_estimators=10, max_depth=20,)\n",
    "    rf.fit(X_train_t, y_train[label])\n",
    "    rf_pred = rf.predict(X_val_t)\n",
    "    print(f\"Random Forest Accuracy: {accuracy_score(y_val[label], rf_pred)}\")\n",
    "    rf_cv_score = cross_val_score(rf, X_train_t, y_train[label], cv=5).mean()\n",
    "    print(f\"Random Forest Mean CV Score: {rf_cv_score}\")\n",
    "    print(\"\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    print(f\"Training for {label}\")\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    # Create a RandomForestClassifier object\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # Create a GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "    # Fit the GridSearchCV object to the data\n",
    "    grid_search.fit(X_train_t, y_train[label])\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create the Random Forest object\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Wrap it with MultiOutputClassifier\n",
    "multi_target_forest = MultiOutputClassifier(rf, n_jobs=-1)\n",
    "\n",
    "multi_target_forest.fit(X_train, y_train)\n",
    "\n",
    "cv_scores = cross_val_score(multi_target_forest, X_train, y_train, cv=5)\n",
    "print(f'Mean CV Score: {cv_scores.mean()}')\n",
    "\n",
    "y_pred = multi_target_forest.predict(X_val)\n",
    "\n",
    "print('Accuracy Score:', accuracy_score(y_val, y_pred))\n",
    "print('Classification Report:\\n', classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ROI = ['release_month', 'rated', 'collection', \n",
    "                  \n",
    "                'overview_vector',  'tagline_vector', 'plot_vector',\n",
    "                'overview_sentiment', \n",
    "                 'plot_sentiment', 'era', \n",
    "                'action', 'adventure', 'animation', 'comedy', 'crime', 'drama',\n",
    "                'family', 'fantasy', 'history', 'horror', 'music', 'mystery', 'romance',\n",
    "                'science fiction', 'thriller', 'war', 'western', \n",
    "                'num_production_companies', \n",
    "                'producer_popularity',  'director_popularity', 'writer_popularity',\n",
    "                'number_crew_members',\n",
    "                'average_cast_popularity', \n",
    "                'numerical_ROI_category', 'numerical_rating_category', 'numerical_award_category']\n",
    "\n",
    "dataset_df = df[features_ROI].copy()\n",
    "\n",
    "from sklearn.model_selection import train_test_split, train_test_split\n",
    "df_full_train, df_test = train_test_split(dataset_df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "\n",
    "X_train = df_train.reset_index(drop=True)\n",
    "X_val = df_val.reset_index(drop=True)\n",
    "X_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train.numerical_ROI_category\n",
    "y_val = df_val.numerical_ROI_category\n",
    "y_test = df_test.numerical_ROI_category\n",
    "\n",
    "X_train.drop(['numerical_ROI_category', 'numerical_rating_category', 'numerical_award_category'], axis=1, inplace=True)\n",
    "X_val.drop(['numerical_ROI_category', 'numerical_rating_category', 'numerical_award_category'], axis=1, inplace=True)\n",
    "X_test.drop(['numerical_ROI_category', 'numerical_rating_category', 'numerical_award_category'], axis=1, inplace=True)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Now use X_train_scaled and X_val_scaled instead of X_train and X_val in your loop.\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train_t = dv.fit_transform(X_train.to_dict(orient='records'))\n",
    "X_val_t = dv.transform(X_val.to_dict(orient='records'))\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_t = scaler.fit_transform(X_train_t)\n",
    "X_val_t = scaler.transform(X_val_t)\n",
    "\n",
    "\n",
    "# Train a model using all features\n",
    "label = 'numerical_ROI_category'\n",
    "model = LogisticRegression(solver='liblinear', C=1, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_t, y_train)\n",
    "original_accuracy = accuracy_score(y_val, model.predict(X_val_t))\n",
    "print(\"accuracy:\", original_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ROI = ['release_month', 'release_year', 'rated', 'collection', \n",
    "                  \n",
    "                'overview_vector',  'tagline_vector', 'plot_vector',\n",
    "                'overview_sentiment', \n",
    "                 'plot_sentiment', 'era', \n",
    "                'action', 'adventure', 'animation', 'comedy', 'crime', 'drama',\n",
    "                'family', 'fantasy', 'history', 'horror', 'music', 'mystery', 'romance',\n",
    "                'science fiction', 'thriller', 'war', 'western', \n",
    "                'num_production_companies', \n",
    "                'producer_popularity',  'director_popularity', 'writer_popularity',\n",
    "                'number_crew_members',\n",
    "                'average_cast_popularity', \n",
    "                'numerical_ROI_category', 'numerical_rating_category', 'numerical_award_category']\n",
    "\n",
    "dataset_df = df[features_ROI].copy()\n",
    "\n",
    "from sklearn.model_selection import train_test_split, train_test_split\n",
    "df_full_train, df_test = train_test_split(dataset_df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "\n",
    "X_train = df_train.reset_index(drop=True)\n",
    "X_val = df_val.reset_index(drop=True)\n",
    "X_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train.numerical_ROI_category\n",
    "y_val = df_val.numerical_ROI_category\n",
    "y_test = df_test.numerical_ROI_category\n",
    "\n",
    "X_train.drop(['numerical_ROI_category', 'numerical_rating_category', 'numerical_award_category'], axis=1, inplace=True)\n",
    "X_val.drop(['numerical_ROI_category', 'numerical_rating_category', 'numerical_award_category'], axis=1, inplace=True)\n",
    "X_test.drop(['numerical_ROI_category', 'numerical_rating_category', 'numerical_award_category'], axis=1, inplace=True)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Now use X_train_scaled and X_val_scaled instead of X_train and X_val in your loop.\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train_t = dv.fit_transform(X_train.to_dict(orient='records'))\n",
    "X_val_t = dv.transform(X_val.to_dict(orient='records'))\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_t = scaler.fit_transform(X_train_t)\n",
    "X_val_t = scaler.transform(X_val_t)\n",
    "\n",
    "\n",
    "# Train a model using all features\n",
    "label = 'numerical_ROI_category'\n",
    "model = LogisticRegression(solver='liblinear', C=1, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_t, y_train)\n",
    "original_accuracy = accuracy_score(y_val, model.predict(X_val_t))\n",
    "print(\"accuracy:\", original_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'lbfgs'],\n",
    "    #'max_iter': [100, 500, 1000]\n",
    "}\n",
    "#estimator = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_t, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best parameters: {best_params}')\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "print(f'Best cross-validation score: {best_score}')\n",
    "\n",
    "val_score = grid_search.score(X_val_t, y_val)\n",
    "print(f'Validation score: {val_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "lasso = LassoCV(cv=5)\n",
    "lasso.fit(X_train_t, y_train)\n",
    "lasso_coef = lasso.coef_\n",
    "lasso_coef\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create an array of feature names\n",
    "feature_names = np.array(dv.get_feature_names_out())\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.barh(feature_names, lasso_coef)\n",
    "plt.title('Lasso coefficients')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('Feature Name')\n",
    "plt.show()\n",
    "\n",
    "# Identify and print the features with a coefficient of zero\n",
    "zero_features = feature_names[lasso_coef == 0]\n",
    "print('Features with zero coefficient:', zero_features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_camp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
