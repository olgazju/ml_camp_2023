{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Movie Data Collection Script\n",
    "\n",
    "This script is designed to fetch movie-related data from TheMovieDB API then by imdb_id get metadata from OMDB API and unite those datasets, and store the collected data in Parquet format. It also creates a dataset from TheMovieDB API credits. Here's a breakdown of its functionalities:\n",
    "\n",
    "### 1. **Importing Required Libraries**:\n",
    "   - Essential libraries such as `requests`, `os`, `backoff`, and `pandas` are imported for handling HTTP requests, environment variables, retry logic, and data manipulation respectively.\n",
    "\n",
    "### 2. **Header Configuration**:\n",
    "HTTP headers are configured with authorization using an API token retrieved from environment variables.\n",
    "You should get token accees from https://developer.themoviedb.org/reference/intro/getting-started for TheMovieDB API and OMDB API key from https://www.omdbapi.com/apikey.aspx. OMDB API key is limited to 1000 calls per day for free.\n",
    "After you get those keys you should create .env file in the root folder and fill it with values:\n",
    "\n",
    "        API_KEY=\n",
    "        API_TOKEN=\n",
    "        OMDB_KEY=\n",
    "\n",
    "### 3. **Retry Logic**:\n",
    "   - A custom retry logic is defined using the `backoff` library to manage HTTP errors, particularly focusing on status code 429 (Too Many Requests).\n",
    "\n",
    "### 4. **API Call Function**:\n",
    "   - A function `call_get(url)` is defined to make GET requests to the specified URL and raise exceptions for unsuccessful responses.\n",
    "\n",
    "### 5. **Movie Data Retrieval Functions**:\n",
    "   - `get_latest_movie()`: Fetches the latest movie data from TheMovieDB API.\n",
    "   - `get_movie_credits_by_id(id)`: Obtains movie credits based on the movie ID from TheMovieDB API, with error handling for non-existent movie IDs.\n",
    "   - `get_movie_by_id(id)`: Retrieves movie data by ID from TheMovieDB API, also with error handling for non-existent movie IDs.\n",
    "   - `get_movie_from_omdb(imdb_id, api_key)`: Fetches movie data from the OMDB API using the IMDb ID.\n",
    "\n",
    "### 6. **Bulk Data Collection Functions**:\n",
    "   - `fetch_all_movies(start_id, last_id)` and `fetch_all_credits(start_id, last_id)` are designed to loop through a range of movie IDs, collecting and merging movie data from both TheMovieDB and OMDB APIs, and movie credits from TheMovieDB API respectively.\n",
    "\n",
    "### 7. **Data Normalization and Storage**:\n",
    "   - The script utilizes `pandas` to normalize the collected JSON data into a tabular format, and subsequently stores the data in Parquet files with gzip compression, for both movies and credits data.\n",
    "\n",
    "This script represents a systematic approach to collecting, normalizing, and storing movie-related data from different online sources through API interactions, with robust error handling and retry logic to ensure the reliability of the data collection process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import backoff\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../.env')\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {os.getenv('API_TOKEN')}\"\n",
    "}\n",
    "\n",
    "# Custom retry condition\n",
    "def giveup(exc):\n",
    "    # Don't retry if the exception is not a 429 status\n",
    "    return exc.response.status_code != 429\n",
    "\n",
    "@backoff.on_exception(\n",
    "    backoff.expo,  # Exponential backoff strategy\n",
    "    requests.exceptions.HTTPError,  # Exception to look for\n",
    "    max_tries=10,  # Maximum retry attempts\n",
    "    giveup=giveup  # Function to determine if retry should be aborted\n",
    ")\n",
    "def call_get(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status() \n",
    "    return response.json()\n",
    "\n",
    "def get_latest_movie():\n",
    "    url = \"https://api.themoviedb.org/3/movie/latest\"\n",
    "    return call_get(url)\n",
    "\n",
    "\n",
    "def get_movie_credits_by_id(id):\n",
    "    url = f\"https://api.themoviedb.org/3/movie/{id}/credits?language=en-US\"\n",
    "    try:\n",
    "        return call_get(url)\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if e.response.status_code == 404:\n",
    "            try:\n",
    "                error_response = e.response.json()\n",
    "                if error_response.get('status_code') == 34:\n",
    "                    print(f\"No credits found for ID: {id}\")\n",
    "                    return None\n",
    "                \n",
    "            except ValueError:\n",
    "                print(f\"Received unexpected response: {e.response.text}\")\n",
    "        else:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            raise e\n",
    "\n",
    "\n",
    "def get_movie_by_id(id):\n",
    "    url = f\"https://api.themoviedb.org/3/movie/{id}?language=en-US\"\n",
    "    try:\n",
    "        return call_get(url)\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if e.response.status_code == 404:\n",
    "            try:\n",
    "                error_response = e.response.json()\n",
    "                if error_response.get('status_code') == 34:\n",
    "                    print(f\"No movie found for ID: {id}\")\n",
    "                    return None\n",
    "                \n",
    "            except ValueError:\n",
    "                print(f\"Received unexpected response: {e.response.text}\")\n",
    "        else:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            raise e\n",
    "\n",
    "def get_movie_from_omdb(imdb_id, api_key=os.getenv('OMDB_KEY')):\n",
    "    url = f\"https://www.omdbapi.com/?i={imdb_id}&apikey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status() \n",
    "    return response.json()\n",
    "\n",
    "def fetch_all_movies(start_id, last_id):\n",
    "    all_movies = [] \n",
    "    for id in range(start_id, last_id + 1): \n",
    "        movie = get_movie_by_id(id)\n",
    "        if movie is not None and movie[\"imdb_id\"] and \\\n",
    "            movie['revenue'] !=0 and movie['status'] == 'Released' and \\\n",
    "            movie ['budget'] !=0:\n",
    "            # check this movie in omdb\n",
    "            try: \n",
    "                omdb_json = get_movie_from_omdb(movie[\"imdb_id\"])\n",
    "                merged = {**movie, **omdb_json}\n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                print(f\"OMDB Received response: {e.response.text}\")\n",
    "            all_movies.append(merged)\n",
    "    return all_movies\n",
    "\n",
    "def fetch_all_credits(start_id, last_id):\n",
    "    all_credits = [] \n",
    "    for id in range(start_id, last_id + 1):  \n",
    "        credit = get_movie_credits_by_id(id)\n",
    "        if credit is not None:\n",
    "            all_credits.append(credit)\n",
    "    return all_credits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_movie = get_latest_movie()['id']\n",
    "last_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_movie = 14900\n",
    "all_movies = fetch_all_movies(14801, last_movie)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.json_normalize(all_movies)\n",
    "df.to_parquet(f\"../tmdb/movies_{last_movie}.parquet\", compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(f\"../tmdb/movies_{last_movie}.parquet\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_movie = 14801\n",
    "all_movies = fetch_all_credits(7800, last_movie)\n",
    "\n",
    "df = pd.json_normalize(all_movies)\n",
    "df.to_parquet(f\"../credits/credits_{last_movie}.parquet\", compression='gzip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge files to one for movies data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "\n",
    "def read_parquet_files_to_dataframe(directory_path):\n",
    "    # List all files in the directory\n",
    "    files = [f for f in os.listdir(directory_path) if f.endswith('.parquet')]\n",
    "    \n",
    "    # Initialize an empty list to hold DataFrames\n",
    "    dataframes = []\n",
    "    \n",
    "    # Loop through the files and read each one into a DataFrame\n",
    "    for file in files:\n",
    "        file_path = os.path.join(directory_path, file)\n",
    "        parquet_file = pq.ParquetFile(file_path)\n",
    "        df = parquet_file.read().to_pandas()\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    # Concatenate all the DataFrames into a single DataFrame\n",
    "    merged_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    return merged_dataframe\n",
    "\n",
    "\n",
    "\n",
    "# Call the function\n",
    "movies_dataframe = read_parquet_files_to_dataframe('../tmdb/')\n",
    "movies_dataframe=movies_dataframe.drop_duplicates(subset=['id'])\n",
    "\n",
    "\n",
    "movies_dataframe.to_parquet('../data/movies.parquet', compression='gzip')\n",
    "\n",
    "# Call the function\n",
    "credits_dataframe = read_parquet_files_to_dataframe('../credits//')\n",
    "credits_dataframe=credits_dataframe.drop_duplicates(subset=['id'])\n",
    "\n",
    "\n",
    "credits_dataframe.to_parquet('../data/credits.parquet', compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_camp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
