{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python Movie Data Collection Script Overview**\n",
    "\n",
    "This script gathers movie data and credits from TheMovieDB API and additional metadata from the OMDB API, combining them and saving in Parquet format.\n",
    "\n",
    "1. **Importing Libraries**: I use `requests` for HTTP requests, `backoff` for retry logic, and `pandas` for data handling.\n",
    "2. **Setting Up Headers**: I configure HTTP headers with API tokens from TheMovieDB and OMDB APIs for authorization. The OMDB API key allows up to 1000 free calls per day.\n",
    "\n",
    "   After acquiring the keys, create a .env file in the root folder and populate it with the following values:\n",
    "\n",
    "   ```\n",
    "   API_KEY=\n",
    "   API_TOKEN=\n",
    "   OMDB_KEY=\n",
    "   ```\n",
    "\n",
    "\n",
    "3. **Fetching Movie Data**:\n",
    "\n",
    "* get_latest_movie(): Fetches the latest movie id from TheMovieDB API.\n",
    "* get_movie_by_id(id): Retrieves movie data by ID from TheMovieDB API, also with error handling for non-existent movie IDs.\n",
    "* get_movie_from_omdb(imdb_id, api_key): Fetches movie data from the OMDB API using the IMDb ID.\n",
    "* fetch_all_movies(start_id, last_id) is created to loop through a range of movie IDs, collecting and merging movie and credits data from both TheMovieDB and OMDB APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import backoff\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional, Union, Dict, List\n",
    "\n",
    "load_dotenv('../.env')\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {os.getenv('API_TOKEN')}\"\n",
    "}\n",
    "\n",
    "\n",
    "# Custom retry condition to handle HTTP 429 status code (Too Many Requests)\n",
    "def giveup(exc: requests.exceptions.HTTPError) -> bool:\n",
    "    \"\"\"Determines whether to give up a retry attempt.\n",
    "    \n",
    "    Args:\n",
    "        exc (requests.exceptions.HTTPError): The exception raised during the HTTP request.\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if the exception's status code is not 429 - Too Many Requests, otherwise False.\n",
    "    \"\"\"\n",
    "    return exc.response.status_code != 429\n",
    "\n",
    "\n",
    "@backoff.on_exception(\n",
    "    backoff.expo,  # Exponential backoff strategy for Too Many Requests error\n",
    "    requests.exceptions.HTTPError,  # Exception to look for\n",
    "    max_tries=10,  # Maximum retry attempts\n",
    "    giveup=giveup  # Function to determine if retry should be aborted\n",
    ")\n",
    "def call_get(url: str) -> Union[Dict, None]:\n",
    "    \"\"\"Makes a GET request to a specified URL and handles potential errors.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The URL to send a GET request to.\n",
    "        \n",
    "    Returns:\n",
    "        dict: The JSON response from the GET request.\n",
    "    \"\"\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status() \n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def get_latest_movie() -> Dict:\n",
    "    \"\"\"Fetches the latest movie data from TheMovieDB API.\n",
    "    \n",
    "    Returns:\n",
    "        dict: The latest movie data.\n",
    "    \"\"\"\n",
    "    url = \"https://api.themoviedb.org/3/movie/latest\"\n",
    "    return call_get(url)\n",
    "\n",
    "\n",
    "def get_movie_by_id(id: int) -> Optional[Dict]:\n",
    "    \"\"\"Retrieves movie data by ID from TheMovieDB API.\n",
    "    \n",
    "    Args:\n",
    "        id (int): The ID of the movie.\n",
    "        \n",
    "    Returns:\n",
    "        dict: The movie data, or None if not found.\n",
    "    \"\"\"\n",
    "    url = f\"https://api.themoviedb.org/3/movie/{id}?language=en-US&append_to_response=credits\"\n",
    "    try:\n",
    "        return call_get(url)\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if e.response.status_code == 404:\n",
    "            try:\n",
    "                error_response = e.response.json()\n",
    "                if error_response.get('status_code') == 34:\n",
    "                    print(f\"No movie found for ID: {id}\")\n",
    "                    return None\n",
    "                \n",
    "            except ValueError:\n",
    "                print(f\"Received unexpected response: {e.response.text}\")\n",
    "        else:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            raise e\n",
    "\n",
    "def get_movie_from_omdb(imdb_id: str, api_key: str = os.getenv('OMDB_KEY')) -> Dict:\n",
    "    \"\"\"Fetches movie data from the OMDB API using the IMDb ID.\n",
    "    \n",
    "    Args:\n",
    "        imdb_id (str): The IMDb ID of the movie.\n",
    "        api_key (str): The API key for OMDB API.\n",
    "        \n",
    "    Returns:\n",
    "        dict: The movie data from OMDB API.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.omdbapi.com/?i={imdb_id}&apikey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status() \n",
    "    return response.json()\n",
    "\n",
    "def fetch_all_movies(start_id: int, last_id: int) -> List[Dict]:\n",
    "    \"\"\"Loops through a range of movie IDs, collecting and merging movie data from both APIs.\n",
    "    \n",
    "    Args:\n",
    "        start_id (int): The starting movie ID.\n",
    "        last_id (int): The ending movie ID.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of merged movie data dictionaries.\n",
    "    \"\"\"\n",
    "    all_movies = [] \n",
    "    for id in range(start_id, last_id + 1): \n",
    "        movie = get_movie_by_id(id)\n",
    "        if movie is not None and movie[\"imdb_id\"] and \\\n",
    "            movie['revenue'] !=0 and movie['status'] == 'Released' and \\\n",
    "            movie ['budget'] !=0:\n",
    "            # check this movie in omdb\n",
    "            try: \n",
    "                omdb_json = get_movie_from_omdb(movie[\"imdb_id\"])\n",
    "                merged = {**movie, **omdb_json}\n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                print(f\"OMDB Received response: {e.response.text}\")\n",
    "            all_movies.append(merged)\n",
    "    return all_movies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the lastest avaliable movie id from TMDB API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_movie = get_latest_movie()['id']\n",
    "last_movie\n",
    "\n",
    "# current last movie 80001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ID of the last movie to be fetched\n",
    "last_movie = 180000\n",
    "\n",
    "# Set the ID of the movie to start fetching\n",
    "start_movie = 171710\n",
    "\n",
    "\n",
    "# Fetch all movies metadata from ID start_movie to last_movie\n",
    "all_movies = fetch_all_movies(start_movie, last_movie)\n",
    "\n",
    "df = pd.json_normalize(all_movies)\n",
    "df.to_parquet(f\"../tmdb/movies_{last_movie}.parquet\", compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "\n",
    "def read_parquet_files_to_dataframe(directory_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Reads all parquet files from a specified directory and merges them into a single DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        directory_path (str): The path to the directory containing the parquet files.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the merged data from all parquet files.\n",
    "    \"\"\"\n",
    "    # List all files in the directory\n",
    "    files = [f for f in os.listdir(directory_path) if f.endswith('.parquet')]\n",
    "    \n",
    "    dataframes = []\n",
    "    \n",
    "    # Loop through the files and read each one into a DataFrame\n",
    "    for file in files:\n",
    "        file_path = os.path.join(directory_path, file)\n",
    "        parquet_file = pq.ParquetFile(file_path)\n",
    "        df = parquet_file.read().to_pandas()\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    # Concatenate all the DataFrames into a single DataFrame\n",
    "    merged_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    return merged_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOVIES\n",
    "# Call the function to read and merge all parquet files in the specified directory into a DataFrame\n",
    "movies_dataframe = read_parquet_files_to_dataframe('../tmdb/')\n",
    "# Remove duplicate rows based on the 'id' column of the DataFrame\n",
    "movies_dataframe=movies_dataframe.drop_duplicates(subset=['id'])\n",
    "\n",
    "movies_dataframe=movies_dataframe.rename(columns={\"credits.cast\": \"cast\", \"credits.crew\": \"crew\"})\n",
    "movies_dataframe.columns\n",
    "# Save the deduplicated DataFrame to a new Parquet file with gzip compression in the specified directory\n",
    "movies_dataframe.to_parquet('../data/new_pack.parquet', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dataframe = read_parquet_files_to_dataframe('../data/')\n",
    "movies_dataframe.to_parquet('../data/full_pack.parquet', compression='gzip')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_camp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
